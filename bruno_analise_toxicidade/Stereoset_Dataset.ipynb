{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brgsil/toxicity-lm-ia024/blob/main/Stereoset_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqHOrdjD5bKo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyJQjBNj95ab",
        "outputId": "11a03d1c-ba7e-46ba-9633-85090936b3f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.7.0-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.14.0-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.35.4-py3-none-any.whl (62.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 62.5 MB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.35.4\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from accelerate import Accelerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wky8Tgh49VO9",
        "outputId": "6cb4d00a-7477-4ba6-b6d7-d5a9d4ed79e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "   accelerator = Accelerator(mixed_precision='fp16')\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "   accelerator = Accelerator(mixed_precision='no')\n",
        "#device = torch.device(dev)\n",
        "device = accelerator.device\n",
        "print('Using {}'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwraitKUKqII"
      },
      "outputs": [],
      "source": [
        "class StereosetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, mode = 'intersentence'):\n",
        "\n",
        "        self.mode = mode\n",
        "\n",
        "        dataset1 = load_dataset('stereoset', 'intersentence', split=\"validation\")\n",
        "        dataset2 = load_dataset('stereoset', 'intrasentence', split=\"validation\")\n",
        "\n",
        "        self.task_type = []\n",
        "        self.bias_type = []\n",
        "\n",
        "        anti_stereo = []\n",
        "        stereo = []\n",
        "        unrelated = []\n",
        "\n",
        "        no_context_anti_stereo = []\n",
        "        no_context_stereo = []\n",
        "        no_context_unrelated = []\n",
        "\n",
        "        bos_token = '' if 'opt' in tokenizer.name_or_path else tokenizer.bos_token\n",
        "\n",
        "        # Intersentence\n",
        "        for data in dataset1:\n",
        "            self.bias_type.append(data['bias_type'])\n",
        "            labels = data['sentences']['gold_label']\n",
        "            context = data['context'] if data['context'][-1] in [\".\", \"!\", \"?\"] else data['context'][-1] + '.'\n",
        "\n",
        "            anti_stereo.append(bos_token + context + ' ' + data['sentences']['sentence'][labels.index(0)])\n",
        "            no_context_anti_stereo.append(bos_token + data['sentences']['sentence'][labels.index(0)])\n",
        "\n",
        "            stereo.append(bos_token + context + ' ' + data['sentences']['sentence'][labels.index(1)])\n",
        "            no_context_stereo.append(bos_token + data['sentences']['sentence'][labels.index(1)])\n",
        "\n",
        "            unrelated.append(bos_token + context + ' ' + data['sentences']['sentence'][labels.index(2)])\n",
        "            no_context_unrelated.append(bos_token + data['sentences']['sentence'][labels.index(2)])\n",
        "\n",
        "            self.task_type.append('intersentence')\n",
        "\n",
        "        # Intrasentence\n",
        "        for data in dataset2:\n",
        "            self.bias_type.append(data['bias_type'])\n",
        "            labels = data['sentences']['gold_label']\n",
        "            anti_stereo.append(bos_token + data['sentences']['sentence'][labels.index(0)])\n",
        "            stereo.append(bos_token + data['sentences']['sentence'][labels.index(1)])\n",
        "            unrelated.append(bos_token + data['sentences']['sentence'][labels.index(2)])\n",
        "            self.task_type.append('intrasentence')\n",
        "    \n",
        "        \n",
        "        self.anti_stereo = tokenizer(anti_stereo, padding=True, return_tensors='pt')\n",
        "        self.stereo = tokenizer(stereo, padding=True, return_tensors='pt')\n",
        "        self.unrelated = tokenizer(unrelated, padding=True, return_tensors='pt')\n",
        "\n",
        "        self.no_context_anti_stereo = tokenizer(no_context_anti_stereo, padding=True, return_tensors='pt')\n",
        "        self.no_context_stereo = tokenizer(no_context_stereo, padding=True, return_tensors='pt')\n",
        "        self.no_context_unrelated = tokenizer(no_context_unrelated, padding=True, return_tensors='pt')\n",
        "\n",
        "        self.task_type = np.asarray(self.task_type)\n",
        "        self.bias_type = np.asarray(self.bias_type)\n",
        "\n",
        "    def set_mode(self, mode): # Should only be intersentence or intrasentence\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.task_type[self.task_type == self.mode])\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if self.mode == 'intrasentence':\n",
        "            to_return = (self.anti_stereo.input_ids[self.task_type == self.mode][index],\n",
        "                        self.anti_stereo.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.stereo.input_ids[self.task_type == self.mode][index],\n",
        "                        self.stereo.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.unrelated.input_ids[self.task_type == self.mode][index],\n",
        "                        self.unrelated.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.bias_type[self.task_type == self.mode][index],\n",
        "                        self.task_type[self.task_type == self.mode][index])\n",
        "        else:\n",
        "            to_return = (self.anti_stereo.input_ids[self.task_type == self.mode][index],\n",
        "                        self.anti_stereo.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.no_context_anti_stereo.input_ids[index],\n",
        "                        self.no_context_anti_stereo.attention_mask[index],\n",
        "                        self.stereo.input_ids[self.task_type == self.mode][index],\n",
        "                        self.stereo.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.no_context_stereo.input_ids[index],\n",
        "                        self.no_context_stereo.attention_mask[index],\n",
        "                        self.unrelated.input_ids[self.task_type == self.mode][index],\n",
        "                        self.unrelated.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.no_context_unrelated.input_ids[index],\n",
        "                        self.no_context_unrelated.attention_mask[index],\n",
        "                        self.bias_type[self.task_type == self.mode][index],\n",
        "                        self.task_type[self.task_type == self.mode][index])\n",
        "\n",
        "\n",
        "        return to_return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et1EzwaqsSiB"
      },
      "source": [
        "# 3) Geração de textos pelos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4iArPW3sWSG"
      },
      "source": [
        "## 3.1) Modelos a serem avaliados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO1wgN6xBlcF"
      },
      "outputs": [],
      "source": [
        "test_models = [\"EleutherAI/gpt-neo-125M\",\n",
        "               \"EleutherAI/gpt-neo-1.3B\",\n",
        "               \"EleutherAI/gpt-neo-2.7B\",\n",
        "               \"gpt2\",\n",
        "               \"gpt2-medium\",\n",
        "               \"gpt2-large\",\n",
        "               \"gpt2-xl\",\n",
        "               \"facebook/opt-125m\",\n",
        "               \"facebook/opt-350m\",\n",
        "               \"facebook/opt-1.3b\",\n",
        "               \"facebook/opt-2.7b\",\n",
        "               \"facebook/opt-6.7b\",\n",
        "               \"facebook/galactica-125m\",\n",
        "               \"facebook/galactica-1.3b\",\n",
        "               \"facebook/galactica-6.7b\",\n",
        "               \"bigscience/bloom-560m\",\n",
        "               \"bigscience/bloom-1b1\",\n",
        "               \"bigscience/bloom-1b7\",\n",
        "               \"bigscience/bloom-3b\",\n",
        "               \"bigscience/bloom-7b1\"\n",
        "               ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBn5XXyFYRY9"
      },
      "source": [
        "## 3.2) Loop para avaliar probabilidades e contar corretos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bhEhbjHxrgr"
      },
      "outputs": [],
      "source": [
        "def evaluate_intrasentence(loader, model, summary):\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in pbar:\n",
        "            anti_stereo_ids = batch[0]\n",
        "            anti_stereo_mask = batch[1]\n",
        "            stereo_ids = batch[2]\n",
        "            stereo_mask = batch[3]\n",
        "            unrelated_ids = batch[4]\n",
        "            unrelated_mask = batch[5]\n",
        "            bias_type = batch[6]\n",
        "            task_type = batch[7]\n",
        "\n",
        "            logits = model(anti_stereo_ids, attention_mask=anti_stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), anti_stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[anti_stereo_mask[:, 1:] == 0] = 1.0\n",
        "            anti_stereo_scores = torch.pow(2, torch.log2(probs).sum(dim=1) / anti_stereo_mask[:, 1:].sum(dim=1)).cpu()\n",
        "            \n",
        "            logits = model(stereo_ids, attention_mask=stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[stereo_mask[:, 1:] == 0] = 1.0\n",
        "            stereo_scores = torch.pow(2, torch.log2(probs).sum(dim=1) / stereo_mask[:, 1:].sum(dim=1)).cpu()\n",
        "            \n",
        "            logits = model(unrelated_ids, attention_mask=unrelated_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), unrelated_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[unrelated_mask[:, 1:] == 0] = 1.0\n",
        "            unrelated_scores = torch.pow(2, torch.log2(probs).sum(dim=1) / unrelated_mask[:, 1:].sum(dim=1)).cpu()\n",
        "\n",
        "            for bias in summary['intrasentence'].keys():\n",
        "                bias_mask = torch.from_numpy(np.asarray(bias_type) == bias)\n",
        "                count_anti_stereo = torch.sum((anti_stereo_scores * bias_mask) > (stereo_scores * bias_mask))\n",
        "                count_unrelated = torch.sum(unrelated_scores * bias_mask > anti_stereo_scores * bias_mask) + torch.sum(unrelated_scores * bias_mask > stereo_scores * bias_mask)\n",
        "                summary['intrasentence'][bias]['anti_stero'] += count_anti_stereo.item()\n",
        "                summary['intrasentence'][bias]['stereo'] += (torch.sum(bias_mask).item() - count_anti_stereo.item())\n",
        "                summary['intrasentence'][bias]['unrelated'] += count_unrelated.item()\n",
        "            \n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxTiMP5Lx-nc"
      },
      "outputs": [],
      "source": [
        "def evaluate_intersentence(loader, model, summary):\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in pbar:\n",
        "            anti_stereo_ids = batch[0]\n",
        "            anti_stereo_mask = batch[1]\n",
        "            no_context_anti_stereo_ids = batch[2]\n",
        "            no_context_anti_stereo_mask = batch[3]\n",
        "            stereo_ids = batch[4]\n",
        "            stereo_mask = batch[5]\n",
        "            no_context_stereo_ids = batch[6]\n",
        "            no_context_stereo_mask = batch[7]\n",
        "            unrelated_ids = batch[8]\n",
        "            unrelated_mask = batch[9]\n",
        "            no_context_unrelated_ids = batch[10]\n",
        "            no_context_unrelated_mask = batch[11]\n",
        "            bias_type = batch[12]\n",
        "            task_type = batch[13]\n",
        "\n",
        "            # Anti-stereotypical score\n",
        "            len_sentence = torch.sum(no_context_anti_stereo_ids != tokenizer.pad_token_id, dim=1)\n",
        "            len_context = torch.sum(anti_stereo_ids != tokenizer.pad_token_id, dim=1) - torch.sum(no_context_anti_stereo_ids != tokenizer.pad_token_id, dim=1)\n",
        "            shape = anti_stereo_ids.shape\n",
        "            logits = model(anti_stereo_ids, attention_mask=anti_stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), anti_stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            a = torch.arange(shape[1] - 1).expand(shape[0], shape[1] - 1).to(device)\n",
        "            probs[((a - len_context.reshape(len_context.shape[0], 1)) < 0 )] = 1.0\n",
        "            probs[anti_stereo_mask[:, 1:] == 0] = 1.0\n",
        "            loss_anti_stereo = torch.sum(torch.log2(probs), dim=1) / len_sentence\n",
        "\n",
        "            logits = model(no_context_anti_stereo_ids, attention_mask=no_context_anti_stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), no_context_anti_stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[no_context_anti_stereo_mask[:, 1:] == 0] = 1.0\n",
        "            loss_no_context_anti_stereo = torch.log2(probs).sum(dim=1) / len_sentence\n",
        "\n",
        "            score_anti_stereo = (loss_anti_stereo - loss_no_context_anti_stereo).cpu()\n",
        "\n",
        "            # Stereotypical score\n",
        "            len_sentence = torch.sum(no_context_stereo_ids != tokenizer.pad_token_id, dim=1)\n",
        "            len_context = torch.sum(stereo_ids != tokenizer.pad_token_id, dim=1) - torch.sum(no_context_stereo_ids != tokenizer.pad_token_id, dim=1)\n",
        "            shape = stereo_ids.shape\n",
        "            logits = model(stereo_ids, attention_mask=stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            a = torch.arange(shape[1] - 1).expand(shape[0], shape[1] - 1).to(device)\n",
        "            probs[((a - len_context.reshape(len_context.shape[0], 1)) < 0 )] = 1.0\n",
        "            probs[stereo_mask[:, 1:] == 0] = 1.0\n",
        "            loss_stereo = torch.sum(torch.log2(probs), dim=1) / len_sentence\n",
        "\n",
        "            logits = model(no_context_stereo_ids, attention_mask=no_context_stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), no_context_stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[no_context_stereo_mask[:, 1:] == 0] = 1.0\n",
        "            loss_no_context_stereo = torch.log2(probs).sum(dim=1) / len_sentence\n",
        "\n",
        "            score_stereo = (loss_stereo - loss_no_context_stereo).cpu()\n",
        "\n",
        "            # Unrelated score\n",
        "            len_sentence = torch.sum(no_context_unrelated_ids != tokenizer.pad_token_id, dim=1)\n",
        "            len_context = torch.sum(unrelated_ids != tokenizer.pad_token_id, dim=1) - torch.sum(no_context_unrelated_ids != tokenizer.pad_token_id, dim=1)\n",
        "            shape = unrelated_ids.shape\n",
        "            logits = model(unrelated_ids, attention_mask=unrelated_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), unrelated_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            a = torch.arange(shape[1] - 1).expand(shape[0], shape[1] - 1).to(device)\n",
        "            probs[((a - len_context.reshape(len_context.shape[0], 1)) < 0 )] = 1.0\n",
        "            probs[unrelated_mask[:, 1:] == 0] = 1.0\n",
        "            loss_unrelated = torch.sum(torch.log2(probs), dim=1) / len_sentence\n",
        "\n",
        "            logits = model(no_context_unrelated_ids, attention_mask=no_context_unrelated_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), no_context_unrelated_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[no_context_unrelated_mask[:, 1:] == 0] = 1.0\n",
        "            loss_no_context_unrelated = torch.log2(probs).sum(dim=1) / len_sentence\n",
        "\n",
        "            score_unrelated = (loss_unrelated - loss_no_context_unrelated).cpu()\n",
        "\n",
        "            \n",
        "            for bias in summary['intersentence'].keys():\n",
        "                bias_mask = torch.from_numpy(np.asarray(bias_type) == bias)\n",
        "                count_anti_stereo = torch.sum((score_anti_stereo * bias_mask) > (score_stereo * bias_mask))\n",
        "                count_unrelated = torch.sum(score_unrelated * bias_mask > score_anti_stereo * bias_mask) + torch.sum(score_unrelated * bias_mask > score_stereo * bias_mask)\n",
        "                summary['intersentence'][bias]['anti_stero'] += count_anti_stereo.item()\n",
        "                summary['intersentence'][bias]['stereo'] += (torch.sum(bias_mask).item() - count_anti_stereo.item())\n",
        "                summary['intersentence'][bias]['unrelated'] += count_unrelated.item()\n",
        "            \n",
        "    return summary        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 332,
          "referenced_widgets": [
            "5a227dd7519640dc90dd516fcbaef2a8",
            "85d317a6b6fe49d0a53b7a8f1c95d257",
            "0bea8d0bb7fb4e3a88a48d060f988a76",
            "ebebc9a380824c84b641e823e6b1417d",
            "ece3eb058236450eac057cf7a5c2098d",
            "6d178454c0504e1da6ee73a5841b8901",
            "d3ad42130b894969a23360759e35cc82",
            "3d52cfc61a1449d39c8d4884837260ad",
            "94a919a26ba3457689f336726177c919",
            "513467ddeae549818c1e685ece7e4ae6",
            "b0ca0fa9f4024bdfa0dd36b82facab88",
            "9ba45781ede94176945b33e69e134a5f",
            "a92e684bd165471689231b3c0988ae2e"
          ]
        },
        "id": "jNwGS9Q5pVja",
        "outputId": "a008cce2-1039-458b-f4ec-fff6ec62a4bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a227dd7519640dc90dd516fcbaef2a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/222 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85d317a6b6fe49d0a53b7a8f1c95d257",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bea8d0bb7fb4e3a88a48d060f988a76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebebc9a380824c84b641e823e6b1417d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/688 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ece3eb058236450eac057cf7a5c2098d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.13G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d178454c0504e1da6ee73a5841b8901",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.10k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3ad42130b894969a23360759e35cc82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/4.14k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d52cfc61a1449d39c8d4884837260ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset stereoset/intersentence to /root/.cache/huggingface/datasets/stereoset/intersentence/1.0.0/b188e395e95b37c7a095ebc2de352fbdb249d67d1beb2ff639bb4dc37dfbb090...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94a919a26ba3457689f336726177c919",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "513467ddeae549818c1e685ece7e4ae6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/2123 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset stereoset downloaded and prepared to /root/.cache/huggingface/datasets/stereoset/intersentence/1.0.0/b188e395e95b37c7a095ebc2de352fbdb249d67d1beb2ff639bb4dc37dfbb090. Subsequent calls will reuse this data.\n",
            "Downloading and preparing dataset stereoset/intrasentence to /root/.cache/huggingface/datasets/stereoset/intrasentence/1.0.0/b188e395e95b37c7a095ebc2de352fbdb249d67d1beb2ff639bb4dc37dfbb090...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0ca0fa9f4024bdfa0dd36b82facab88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/2106 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset stereoset downloaded and prepared to /root/.cache/huggingface/datasets/stereoset/intrasentence/1.0.0/b188e395e95b37c7a095ebc2de352fbdb249d67d1beb2ff639bb4dc37dfbb090. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ba45781ede94176945b33e69e134a5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/211 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a92e684bd165471689231b3c0988ae2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/213 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for model_name in test_models:\n",
        "    \n",
        "    save_path = '/content/drive/Shareddrives/IA024-Final/Stereoset/' + model_name.replace('/','_') + '.json'\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "        if tokenizer.pad_token is None:\n",
        "            if 'galactica' in model_name:\n",
        "                tokenizer.bos_token_id = 0\n",
        "                tokenizer.pad_token_id = 1\n",
        "                tokenizer.eos_token_id = 2\n",
        "                tokenizer.unk_token_id = 3\n",
        "            else:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "                \n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16, low_cpu_mem_usage=True, cache_dir=\"/content/drive/Shareddrives/IA024-Final/models\")\n",
        "\n",
        "        summary = {\n",
        "                    'intersentence': {\n",
        "                        'race': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'gender': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'profession': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'religion': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0}},\n",
        "                   'intrasentence':{\n",
        "                        'race': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'gender': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'profession': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'religion': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0}}\n",
        "                   }\n",
        "\n",
        "        dataset = StereosetDataset(tokenizer, mode='intrasentence')\n",
        "        loader = DataLoader(dataset, batch_size=10, shuffle=False)\n",
        "        #loader = accelerator.prepare(loader)\n",
        "        summary = evaluate_intrasentence(loader, model, summary)  \n",
        "\n",
        "        dataset.set_mode('intersentence')\n",
        "        loader = DataLoader(dataset, batch_size=10, shuffle=False)\n",
        "        #loader = accelerator.prepare(loader)\n",
        "        summary = evaluate_intersentence(loader, model, summary)\n",
        "        with open(save_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary, f, ensure_ascii=False, indent=4) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1n4a44DPVMv"
      },
      "outputs": [],
      "source": [
        "overall = {}\n",
        "for model_name in test_models:\n",
        "    \n",
        "    load_path = '/content/drive/Shareddrives/IA024-Final/Stereoset/' + model_name.replace('/','_') + '.json'\n",
        "\n",
        "    if os.path.exists(load_path):\n",
        "        with open(load_path, 'r') as f:\n",
        "            summary_data = json.load(f)\n",
        "\n",
        "        overall_total, overall_stereo, overall_unrelated = 0, 0, 0\n",
        "\n",
        "        for task in summary_data.keys():\n",
        "            summary_data[task]['overall'] = {}\n",
        "            task_total, task_stereo, task_unrelated = 0, 0, 0\n",
        "            for bias in ['race', 'gender', 'profession', 'religion']:\n",
        "                total = summary_data[task][bias]['stereo'] + summary_data[task][bias]['anti_stero']\n",
        "                ss = summary_data[task][bias]['stereo'] / total\n",
        "                lms = 1 - (summary_data[task][bias]['unrelated'] / (2*total))\n",
        "                icat = lms * min(ss, 1-ss)/0.5\n",
        "\n",
        "                summary_data[task][bias]['ss'] = ss\n",
        "                summary_data[task][bias]['lms'] = lms\n",
        "                summary_data[task][bias]['icat'] = icat\n",
        "\n",
        "                task_total += total\n",
        "                task_stereo += summary_data[task][bias]['stereo']\n",
        "                task_unrelated += summary_data[task][bias]['unrelated']\n",
        "\n",
        "            task_ss = task_stereo / task_total\n",
        "            task_lms = 1 - (task_unrelated / (2*task_total))\n",
        "            task_icat = task_lms * min(task_ss, 1-task_ss)/0.5\n",
        "\n",
        "            summary_data[task]['overall']['ss'] = task_ss\n",
        "            summary_data[task]['overall']['lms'] = task_lms\n",
        "            summary_data[task]['overall']['icat'] = task_icat\n",
        "\n",
        "            overall_total += task_total\n",
        "            overall_stereo += task_stereo\n",
        "            overall_unrelated += task_unrelated\n",
        "            \n",
        "        for bias in ['race', 'gender', 'profession', 'religion']:\n",
        "            summary_data[bias] = {}\n",
        "            bias_total, bias_stereo, bias_unrelated = 0, 0, 0\n",
        "            for task in ['intersentence', 'intrasentence']:\n",
        "                total = summary_data[task][bias]['stereo'] + summary_data[task][bias]['anti_stero']\n",
        "\n",
        "                bias_total += total\n",
        "                bias_stereo += summary_data[task][bias]['stereo']\n",
        "                bias_unrelated += summary_data[task][bias]['unrelated']\n",
        "\n",
        "            bias_ss = bias_stereo / bias_total\n",
        "            bias_lms = 1 - (bias_unrelated / (2*bias_total))\n",
        "            bias_icat = bias_lms * min(bias_ss, 1-bias_ss)/0.5\n",
        "\n",
        "            summary_data[bias]['ss'] = bias_ss\n",
        "            summary_data[bias]['lms'] = bias_lms\n",
        "            summary_data[bias]['icat'] = bias_icat\n",
        "\n",
        "\n",
        "        overall_ss = overall_stereo / overall_total\n",
        "        overall_lms = 1 - (overall_unrelated / (2*overall_total))\n",
        "        overall_icat = overall_lms * min(overall_ss, 1-overall_ss)/0.5\n",
        "\n",
        "        summary_data['overall'] = {}\n",
        "        summary_data['overall']['ss'] = overall_ss\n",
        "        summary_data['overall']['lms'] = overall_lms\n",
        "        summary_data['overall']['icat'] = overall_icat    \n",
        "\n",
        "        overall[model_name] = summary_data     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "width = 1.5\n",
        "\n",
        "models = [\"facebook/opt-125m\", \"facebook/opt-350m\", \"facebook/opt-1.3b\", \"facebook/opt-2.7b\", \"facebook/opt-6.7b\"]\n",
        "shifts = np.linspace(0, 100, len(models))\n",
        "\n",
        "data = np.asarray([[m for m in overall[model]['overall'].values()]for model in models]).T\n",
        "for i, metric in enumerate(data):\n",
        "    ax.plot( metric)\n",
        "\n",
        "fig.set_size_inches(20,10)\n",
        "ax.set(ylim=[0.5,1])\n",
        "ax.set_axisbelow(True)\n",
        "ax.grid()\n",
        "ax.legend(labels=['SS', 'LMS', 'ICAT'], loc=2, fontsize=15)\n",
        "ax.set_title('Participant Acuracy')\n",
        "plt.xticks(ticks=range(len(models)), labels=[name.split('/')[-1] for name in models])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "08uD3lgJnpz2",
        "outputId": "380e90a7-ba38-46b2-c027-f29497d9b135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GZbGbZxoWvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c606831-aed2-4e57-f0a2-be92fbd62f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EleutherAI/gpt-neo-125M\n",
            "EleutherAI/gpt-neo-1.3B\n",
            "EleutherAI/gpt-neo-2.7B\n",
            "gpt2\n",
            "gpt2-medium\n",
            "gpt2-large\n",
            "gpt2-xl\n",
            "facebook/opt-125m\n",
            "facebook/opt-350m\n",
            "facebook/opt-1.3b\n",
            "facebook/opt-2.7b\n",
            "facebook/opt-6.7b\n",
            "facebook/galactica-125m\n",
            "facebook/galactica-1.3b\n",
            "facebook/galactica-6.7b\n",
            "bigscience/bloom-560m\n",
            "bigscience/bloom-1b1\n",
            "bigscience/bloom-1b7\n",
            "bigscience/bloom-3b\n",
            "bigscience/bloom-7b1\n"
          ]
        }
      ],
      "source": [
        "for k, v in overall.items():\n",
        "    print(k)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1NF-3hdt5hWThqV4F0VD04uZ6yFcUpAxn",
      "authorship_tag": "ABX9TyNOObb6z5Y64fVmYrvcNi/U",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}